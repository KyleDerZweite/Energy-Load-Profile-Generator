import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import matplotlib.dates as mdates
from typing import Dict, List, Optional, Any, Tuple
import logging
import os
from scipy import stats
try:
    from sklearn.metrics import mean_squared_error, r2_score
    HAS_SKLEARN = True
except ImportError:
    HAS_SKLEARN = False
import json

class LoadProfileAnalyzer:
    """Enhanced intelligent load profile analyzer with device learning analytics."""

    def __init__(self, config: Dict, config_manager=None):
        self.config = config
        self.config_manager = config_manager
        self.logger = logging.getLogger(__name__)
        
        # Initialize intelligent analytics
        self.learning_analytics = {}
        self.intelligence_metrics = {}
        self.pattern_confidence = {}
        self.device_discovery_results = {}

        # Set up plotting style
        plt.style.use('seaborn-v0_8')
        sns.set_palette("husl")
        
        self.logger.info("ðŸ§  Intelligent Load Profile Analyzer initialized")

    def analyze_load_profile(self, load_data: pd.DataFrame) -> Dict:
        """Comprehensive intelligent analysis of the load profile with device learning analytics."""

        self.logger.info("ðŸ”¬ Performing intelligent load profile analysis...")

        analysis = {
            'basic_statistics': self._calculate_basic_stats(load_data),
            'temporal_patterns': self._analyze_temporal_patterns(load_data),
            'weather_correlation': self._analyze_weather_correlation(load_data),
            'peak_analysis': self._analyze_peaks(load_data),
            'device_breakdown': self._analyze_device_breakdown(load_data),
            'intelligence_metrics': self._analyze_intelligence_metrics(load_data),
            'learning_analysis': self._analyze_learning_patterns(load_data),
            'device_discovery': self._analyze_device_discovery(load_data),
            'pattern_confidence': self._analyze_pattern_confidence(load_data),
            'building_efficiency': self._analyze_building_efficiency(load_data),
            'adaptation_metrics': self._analyze_adaptation_effectiveness(load_data)
        }

        return analysis

    def _calculate_basic_stats(self, load_data: pd.DataFrame) -> Dict:
        """Calculate basic load statistics."""
        total_power = load_data['total_power']

        # Time intervals (assuming 15-minute data)
        interval_hours = 0.25

        stats = {
            'total_energy_kwh': total_power.sum() * interval_hours / 1000,
            'average_power_w': total_power.mean(),
            'max_power_w': total_power.max(),
            'min_power_w': total_power.min(),
            'std_power_w': total_power.std(),
            'peak_to_average_ratio': total_power.max() / total_power.mean(),
            'load_factor': total_power.mean() / total_power.max(),
            'data_points': len(load_data),
            'time_span_days': (load_data.index.max() - load_data.index.min()).days,
            'temperature_range': {
                'min': load_data['temperature'].min(),
                'max': load_data['temperature'].max(),
                'mean': load_data['temperature'].mean(),
                'std': load_data['temperature'].std()
            }
        }

        # Percentiles
        percentiles = [5, 10, 25, 50, 75, 90, 95, 99]
        stats['power_percentiles'] = {
            f'p{p}': total_power.quantile(p/100) for p in percentiles
        }

        # Enhanced statistics with intelligence insights
        stats['intelligence_score'] = self._calculate_intelligence_score(load_data)
        stats['realism_factor'] = self._calculate_realism_factor(load_data)
        stats['learning_confidence'] = self._calculate_learning_confidence(load_data)
        
        return stats

    def _calculate_device_stats(self, load_data: pd.DataFrame, device_col: str) -> Dict:
        """Calculate statistics for a specific device including peak power info."""
        device_name = device_col.replace('_power', '')
        device_consumption = load_data[device_col].sum() * 0.25 / 1000  # kWh

        # Get peak power from config if available
        if self.config_manager:
            devices_config = self.config_manager.get_all_devices()
        else:
            devices_config = self.config.get('devices', {})
        peak_power = devices_config.get(device_name, {}).get('peak_power', load_data[device_col].max())

        total_consumption = load_data['total_power'].sum() * 0.25 / 1000  # kWh

        return {
            'total_kwh': device_consumption,
            'percentage': (device_consumption / total_consumption * 100) if total_consumption > 0 else 0,
            'average_power_w': load_data[device_col].mean(),
            'max_power_w': load_data[device_col].max(),
            'min_power_w': load_data[device_col].min(),
            'peak_power_w': peak_power,
            'capacity_factor': load_data[device_col].mean() / peak_power if peak_power > 0 else 0,
            'peak_capacity_factor': load_data[device_col].max() / peak_power if peak_power > 0 else 0,
            'utilization_rate': (load_data[device_col] > 0).mean()  # Fraction of time device is on
        }

    def _analyze_temporal_patterns(self, load_data: pd.DataFrame) -> Dict:
        """Analyze temporal patterns in energy consumption."""
        patterns = {}

        # 15-minute interval patterns (96 intervals per day)
        if self.config.get('analysis', {}).get('include_hourly_patterns', True):
            # Create 15-minute interval index (0-95)
            load_data['interval_15min'] = (load_data.index.hour * 4) + (load_data.index.minute // 15)
            interval_avg = load_data.groupby('interval_15min')['total_power'].agg(['mean', 'std', 'min', 'max'])
            patterns['interval_15min'] = interval_avg.to_dict('index')

            # Also keep hourly patterns for backward compatibility
            load_data['hour'] = load_data.index.hour
            hourly_avg = load_data.groupby('hour')['total_power'].agg(['mean', 'std', 'min', 'max'])
            patterns['hourly'] = hourly_avg.to_dict('index')

        # Daily patterns (day of week)
        load_data['weekday'] = load_data.index.day_name()
        daily_avg = load_data.groupby('weekday')['total_power'].agg(['mean', 'std'])
        patterns['weekly'] = daily_avg.to_dict('index')

        # Monthly patterns
        if self.config.get('analysis', {}).get('include_monthly_patterns', True):
            load_data['month'] = load_data.index.month
            monthly_avg = load_data.groupby('month')['total_power'].agg(['mean', 'std', 'sum'])
            patterns['monthly'] = monthly_avg.to_dict('index')

        # Seasonal patterns
        if self.config.get('analysis', {}).get('include_seasonal_analysis', True):
            def get_season(month):
                if month in [12, 1, 2]: return 'Winter'
                elif month in [3, 4, 5]: return 'Spring'
                elif month in [6, 7, 8]: return 'Summer'
                else: return 'Autumn'

            load_data['season'] = load_data['month'].apply(get_season)
            seasonal_avg = load_data.groupby('season')['total_power'].agg(['mean', 'std', 'sum'])
            patterns['seasonal'] = seasonal_avg.to_dict('index')

        return patterns

    def _analyze_weather_correlation(self, load_data: pd.DataFrame) -> Dict:
        """Analyze correlation between weather and energy consumption."""
        if not self.config.get('analysis', {}).get('include_temperature_correlation', True):
            return {}

        correlations = {}

        # Temperature correlation
        temp_corr = load_data['total_power'].corr(load_data['temperature'])
        correlations['temperature'] = temp_corr

        # Humidity correlation (if available)
        if 'humidity' in load_data.columns:
            humidity_corr = load_data['total_power'].corr(load_data['humidity'])
            correlations['humidity'] = humidity_corr

        # Temperature bins analysis
        load_data['temp_bin'] = pd.cut(load_data['temperature'],
                                       bins=10, labels=False, duplicates='drop')
        if 'temp_bin' in load_data.columns and not load_data['temp_bin'].isna().all():
            temp_bin_avg = load_data.groupby('temp_bin')['total_power'].mean()
            correlations['temperature_bins'] = temp_bin_avg.to_dict()

        return correlations

    def _analyze_peaks(self, load_data: pd.DataFrame) -> Dict:
        """Analyze peak consumption patterns."""
        if not self.config.get('analysis', {}).get('include_peak_analysis', True):
            return {}

        total_power = load_data['total_power']

        # Define peak thresholds
        p95 = total_power.quantile(0.95)
        p99 = total_power.quantile(0.99)

        peak_analysis = {
            'peak_threshold_95': p95,
            'peak_threshold_99': p99,
            'peak_events_95': (total_power >= p95).sum(),
            'peak_events_99': (total_power >= p99).sum(),
            'peak_duration_hours_95': (total_power >= p95).sum() * 0.25,
            'peak_duration_hours_99': (total_power >= p99).sum() * 0.25
        }

        # Peak timing analysis
        peak_data = load_data[total_power >= p95].copy()
        if not peak_data.empty:
            peak_analysis['peak_hours'] = peak_data.groupby('hour_of_day').size().to_dict()
            peak_analysis['peak_months'] = peak_data.groupby(peak_data.index.month).size().to_dict()

        return peak_analysis

    def _analyze_device_breakdown(self, load_data: pd.DataFrame) -> Dict:
        """Analyze individual device contributions."""
        device_columns = [col for col in load_data.columns if col.endswith('_power')]

        breakdown = {}

        for device_col in device_columns:
            device_name = device_col.replace('_power', '')
            breakdown[device_name] = self._calculate_device_stats(load_data, device_col)

        # Add intelligent device analytics
        for device_name in breakdown.keys():
            breakdown[device_name].update({
                'intelligence_score': self._calculate_device_intelligence(load_data, f"{device_name}_power"),
                'learning_confidence': self._calculate_device_learning_confidence(device_name),
                'adaptation_effectiveness': self._calculate_device_adaptation(device_name),
                'pattern_realism': self._calculate_device_realism(load_data, f"{device_name}_power")
            })
        
        return breakdown

    def generate_plots(self, load_data: pd.DataFrame, output_dir: str = "plots"):
        """Generate visualization plots."""
        if not self.config.get('analysis', {}).get('generate_plots', True):
            return

        os.makedirs(output_dir, exist_ok=True)
        plot_format = self.config.get('analysis', {}).get('plot_format', 'png')
        plot_dpi = self.config.get('analysis', {}).get('plot_dpi', 300)

        self.logger.info(f"Generating plots in {output_dir}/")

        # 1. Overall load profile (sample period)
        self._plot_load_profile(load_data, output_dir, plot_format, plot_dpi)

        # 2. Daily patterns (15-minute intervals)
        self._plot_daily_patterns_15min(load_data, output_dir, plot_format, plot_dpi)

        # 3. Hourly patterns (traditional view)
        self._plot_daily_patterns_hourly(load_data, output_dir, plot_format, plot_dpi)

        # 4. Temperature correlation
        self._plot_temperature_correlation(load_data, output_dir, plot_format, plot_dpi)

        # 5. Device breakdown
        self._plot_device_breakdown(load_data, output_dir, plot_format, plot_dpi)

        # 6. Monthly patterns
        self._plot_monthly_patterns(load_data, output_dir, plot_format, plot_dpi)

        # 7. Device patterns comparison (15-minute intervals)
        self._plot_device_patterns_15min(load_data, output_dir, plot_format, plot_dpi)
        
        # 8. Individual device load profiles (NEW)
        self._plot_individual_device_profiles(load_data, output_dir, plot_format, plot_dpi)
        
        # 9. Individual device daily patterns (NEW)
        self._plot_individual_device_patterns(load_data, output_dir, plot_format, plot_dpi)
        
        # 10. Intelligence and learning analytics plots
        self._plot_intelligence_metrics(load_data, output_dir, plot_format, plot_dpi)
        self._plot_learning_analysis(load_data, output_dir, plot_format, plot_dpi)
        self._plot_device_intelligence(load_data, output_dir, plot_format, plot_dpi)

    def _plot_load_profile(self, load_data: pd.DataFrame, output_dir: str,
                           plot_format: str, plot_dpi: int):
        """Plot overall load profile."""
        plot_days = self.config.get('analysis', {}).get('plot_days', 14)
        sample_data = load_data.head(plot_days * 24 * 4)  # 15-min intervals

        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10), sharex=True)

        # Power consumption
        ax1.plot(sample_data.index, sample_data['total_power'], linewidth=1, alpha=0.8)
        ax1.set_ylabel('Power Consumption (W)')
        ax1.set_title(f'Energy Load Profile ({plot_days} days sample)')
        ax1.grid(True, alpha=0.3)

        # Temperature
        ax2.plot(sample_data.index, sample_data['temperature'], color='red', linewidth=1)
        ax2.set_ylabel('Temperature (Â°C)')
        ax2.set_xlabel('Date and Time')
        ax2.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.xticks(rotation=45)
        plt.savefig(f"{output_dir}/load_profile.{plot_format}", dpi=plot_dpi, bbox_inches='tight')
        plt.close()

    def _plot_daily_patterns_15min(self, load_data: pd.DataFrame, output_dir: str,
                                   plot_format: str, plot_dpi: int):
        """Plot daily consumption patterns with 15-minute intervals."""
        # Create 15-minute interval index and calculate averages
        load_data_copy = load_data.copy()
        load_data_copy['interval_15min'] = (load_data_copy.index.hour * 4) + (load_data_copy.index.minute // 15)
        interval_avg = load_data_copy.groupby('interval_15min')['total_power'].agg(['mean', 'std'])

        # Create time labels for x-axis (24 hours with 15-min intervals)
        time_labels = []
        for hour in range(24):
            for minute in [0, 15, 30, 45]:
                time_labels.append(f"{hour:02d}:{minute:02d}")

        # Ensure we have exactly 96 intervals
        if len(interval_avg) < 96:
            # Fill missing intervals with zeros
            full_index = range(96)
            interval_avg = interval_avg.reindex(full_index, fill_value=0)

        plt.figure(figsize=(20, 8))

        # Plot mean with error bars for standard deviation
        x_pos = range(len(interval_avg))
        plt.plot(x_pos, interval_avg['mean'], marker='o', linewidth=2, markersize=3, alpha=0.8)
        plt.fill_between(x_pos,
                         interval_avg['mean'] - interval_avg['std'],
                         interval_avg['mean'] + interval_avg['std'],
                         alpha=0.3)

        plt.xlabel('Time of Day (15-minute intervals)')
        plt.ylabel('Average Power Consumption (W)')
        plt.title('Average Daily Consumption Pattern (15-minute intervals)')
        plt.grid(True, alpha=0.3)

        # Set x-axis ticks and labels
        # Show every 2 hours (every 8th interval: 0, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88)
        tick_positions = range(0, 96, 8)
        tick_labels = [time_labels[i] for i in tick_positions]
        plt.xticks(tick_positions, tick_labels, rotation=45)

        # Add vertical lines for midnight, 6am, noon, 6pm
        for hour_mark in [0, 24, 48, 72]:  # 00:00, 06:00, 12:00, 18:00
            plt.axvline(x=hour_mark, color='gray', linestyle='--', alpha=0.5)

        plt.tight_layout()
        plt.savefig(f"{output_dir}/daily_patterns_15min.{plot_format}", dpi=plot_dpi, bbox_inches='tight')
        plt.close()

    def _plot_daily_patterns_hourly(self, load_data: pd.DataFrame, output_dir: str,
                                    plot_format: str, plot_dpi: int):
        """Plot traditional hourly daily consumption patterns."""
        hourly_avg = load_data.groupby(load_data.index.hour)['total_power'].agg(['mean', 'std'])

        plt.figure(figsize=(12, 6))

        # Plot mean with error bars
        plt.errorbar(hourly_avg.index, hourly_avg['mean'], yerr=hourly_avg['std'],
                     marker='o', linewidth=2, markersize=6, capsize=5, alpha=0.8)

        plt.xlabel('Hour of Day')
        plt.ylabel('Average Power Consumption (W)')
        plt.title('Average Daily Consumption Pattern (Hourly)')
        plt.grid(True, alpha=0.3)
        plt.xticks(range(0, 24, 2))

        # Add vertical lines for key times
        plt.axvline(x=6, color='orange', linestyle='--', alpha=0.5, label='6 AM')
        plt.axvline(x=12, color='red', linestyle='--', alpha=0.5, label='12 PM')
        plt.axvline(x=18, color='purple', linestyle='--', alpha=0.5, label='6 PM')
        plt.legend()

        plt.tight_layout()
        plt.savefig(f"{output_dir}/daily_patterns_hourly.{plot_format}", dpi=plot_dpi, bbox_inches='tight')
        plt.close()

    def _plot_device_patterns_15min(self, load_data: pd.DataFrame, output_dir: str,
                                    plot_format: str, plot_dpi: int):
        """Plot device-specific 15-minute interval patterns."""
        device_columns = [col for col in load_data.columns if col.endswith('_power')]

        if not device_columns:
            return

        # Create time labels
        time_labels = []
        for hour in range(24):
            for minute in [0, 15, 30, 45]:
                time_labels.append(f"{hour:02d}:{minute:02d}")

        # Calculate 15-minute patterns for each device
        device_patterns = {}
        for device_col in device_columns:
            device_name = device_col.replace('_power', '').replace('_', ' ').title()
            load_data_copy = load_data.copy()
            load_data_copy['interval_15min'] = (load_data_copy.index.hour * 4) + (load_data_copy.index.minute // 15)
            pattern = load_data_copy.groupby('interval_15min')[device_col].mean()

            # Ensure 96 intervals
            if len(pattern) < 96:
                full_index = range(96)
                pattern = pattern.reindex(full_index, fill_value=0)

            device_patterns[device_name] = pattern

        # Plot all devices on one chart
        plt.figure(figsize=(20, 10))

        colors = plt.cm.tab10(np.linspace(0, 1, len(device_patterns)))
        x_pos = range(96)

        for (device_name, pattern), color in zip(device_patterns.items(), colors):
            plt.plot(x_pos, pattern, marker='o', linewidth=2, markersize=2,
                     label=device_name, alpha=0.8, color=color)

        plt.xlabel('Time of Day (15-minute intervals)')
        plt.ylabel('Average Power Consumption (W)')
        plt.title('Device-Specific Daily Consumption Patterns (15-minute intervals)')
        plt.grid(True, alpha=0.3)
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')

        # Set x-axis ticks and labels (every 2 hours)
        tick_positions = range(0, 96, 8)
        tick_labels_filtered = [time_labels[i] for i in tick_positions]
        plt.xticks(tick_positions, tick_labels_filtered, rotation=45)

        # Add vertical lines for key times
        for hour_mark, label in [(0, '00:00'), (24, '06:00'), (48, '12:00'), (72, '18:00')]:
            plt.axvline(x=hour_mark, color='gray', linestyle='--', alpha=0.5)

        plt.tight_layout()
        plt.savefig(f"{output_dir}/device_patterns_15min.{plot_format}", dpi=plot_dpi, bbox_inches='tight')
        plt.close()

    def _plot_individual_device_profiles(self, load_data: pd.DataFrame, output_dir: str,
                                        plot_format: str, plot_dpi: int):
        """Plot individual device load profiles over time."""
        device_columns = [col for col in load_data.columns if col.endswith('_power')]
        
        if not device_columns:
            return
            
        plot_days = self.config.get('analysis', {}).get('plot_days', 14)
        sample_data = load_data.head(plot_days * 24 * 4)  # 15-min intervals
        
        # Create individual plots directory
        individual_plots_dir = os.path.join(output_dir, 'individual_devices')
        os.makedirs(individual_plots_dir, exist_ok=True)
        
        for device_col in device_columns:
            device_name = device_col.replace('_power', '')
            device_display_name = device_name.replace('_', ' ').title()
            
            # Get device configuration for context
            device_config = {}
            if self.config_manager:
                devices_config = self.config_manager.get_all_devices()
                device_config = devices_config.get(device_name, {})
            else:
                device_config = self.config.get('devices', {}).get(device_name, {})
            
            peak_power = device_config.get('peak_power', sample_data[device_col].max())
            
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10), sharex=True)
            
            # Power consumption over time
            ax1.plot(sample_data.index, sample_data[device_col], linewidth=1, alpha=0.8, color='#2E86AB')
            ax1.axhline(y=peak_power, color='red', linestyle='--', alpha=0.7, label=f'Peak Power: {peak_power:,.0f}W')
            ax1.set_ylabel('Power Consumption (W)')
            ax1.set_title(f'{device_display_name} - Load Profile ({plot_days} days sample)')
            ax1.grid(True, alpha=0.3)
            ax1.legend()
            
            # Capacity utilization
            if peak_power > 0:
                utilization = (sample_data[device_col] / peak_power) * 100
                ax2.fill_between(sample_data.index, utilization, alpha=0.6, color='#A23B72')
                ax2.set_ylabel('Capacity Utilization (%)')
                ax2.set_title(f'{device_display_name} - Capacity Utilization')
                ax2.set_ylim(0, 100)
            else:
                ax2.plot(sample_data.index, sample_data[device_col], linewidth=1, alpha=0.8, color='#A23B72')
                ax2.set_ylabel('Power Consumption (W)')
                ax2.set_title(f'{device_display_name} - Power Consumption')
            
            ax2.grid(True, alpha=0.3)
            ax2.set_xlabel('Date & Time')
            
            # Format x-axis
            ax2.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))
            ax2.xaxis.set_major_locator(mdates.DayLocator(interval=2))
            plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)
            
            plt.tight_layout()
            plt.savefig(f"{individual_plots_dir}/{device_name}_profile.{plot_format}", dpi=plot_dpi, bbox_inches='tight')
            plt.close()
            
    def _plot_individual_device_patterns(self, load_data: pd.DataFrame, output_dir: str,
                                         plot_format: str, plot_dpi: int):
        """Plot individual device daily patterns with configuration comparison."""
        device_columns = [col for col in load_data.columns if col.endswith('_power')]
        
        if not device_columns:
            return
            
        # Create time labels
        time_labels = []
        for hour in range(24):
            for minute in [0, 15, 30, 45]:
                time_labels.append(f"{hour:02d}:{minute:02d}")
        
        # Create individual patterns directory
        patterns_dir = os.path.join(output_dir, 'device_patterns')
        os.makedirs(patterns_dir, exist_ok=True)
        
        for device_col in device_columns:
            device_name = device_col.replace('_power', '')
            device_display_name = device_name.replace('_', ' ').title()
            
            # Calculate actual 15-minute pattern from data
            load_data_copy = load_data.copy()
            load_data_copy['interval_15min'] = (load_data_copy.index.hour * 4) + (load_data_copy.index.minute // 15)
            actual_pattern = load_data_copy.groupby('interval_15min')[device_col].mean()
            
            # Ensure 96 intervals
            if len(actual_pattern) < 96:
                full_index = range(96)
                actual_pattern = actual_pattern.reindex(full_index, fill_value=0)
            
            # Get configured pattern for comparison
            configured_pattern = None
            peak_power = actual_pattern.max()
            
            if self.config_manager:
                devices_config = self.config_manager.get_all_devices()
                device_config = devices_config.get(device_name, {})
            else:
                device_config = self.config.get('devices', {}).get(device_name, {})
            
            if 'daily_pattern' in device_config and 'peak_power' in device_config:
                config_pattern = device_config['daily_pattern']
                device_peak_power = device_config.get('peak_power', peak_power)
                if len(config_pattern) == 96:
                    configured_pattern = [p * device_peak_power for p in config_pattern]
            
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10))
            
            x_pos = range(96)
            
            # Top plot: Actual vs Configured patterns
            ax1.plot(x_pos, actual_pattern, marker='o', linewidth=2, markersize=2,
                    label='Actual Pattern', color='#2E86AB', alpha=0.8)
            
            if configured_pattern:
                ax1.plot(x_pos, configured_pattern, marker='s', linewidth=2, markersize=2,
                        label='Configured Pattern', color='#F18F01', alpha=0.8, linestyle='--')
                ax1.legend()
            
            ax1.set_ylabel('Power Consumption (W)')
            ax1.set_title(f'{device_display_name} - Daily Pattern Comparison')
            ax1.grid(True, alpha=0.3)
            
            # Set x-axis ticks and labels (every 2 hours)
            tick_positions = range(0, 96, 8)
            tick_labels_filtered = [time_labels[i] for i in tick_positions]
            ax1.set_xticks(tick_positions)
            ax1.set_xticklabels(tick_labels_filtered, rotation=45)
            
            # Add vertical lines for key times
            for hour_mark, label in [(0, '00:00'), (24, '06:00'), (48, '12:00'), (72, '18:00')]:
                ax1.axvline(x=hour_mark, color='gray', linestyle=':', alpha=0.5)
                ax1.text(hour_mark, ax1.get_ylim()[1] * 0.9, label, rotation=90, 
                        verticalalignment='top', fontsize=9, alpha=0.7)
            
            # Bottom plot: Utilization percentage
            if peak_power > 0:
                utilization = (actual_pattern / peak_power) * 100
                ax2.fill_between(x_pos, utilization, alpha=0.6, color='#A23B72')
                ax2.set_ylabel('Capacity Utilization (%)')
                ax2.set_title(f'{device_display_name} - Daily Capacity Utilization Pattern')
                ax2.set_ylim(0, 100)
            else:
                ax2.plot(x_pos, actual_pattern, linewidth=2, color='#A23B72', alpha=0.8)
                ax2.set_ylabel('Power Consumption (W)')
                ax2.set_title(f'{device_display_name} - Daily Power Pattern')
            
            ax2.grid(True, alpha=0.3)
            ax2.set_xlabel('Time of Day (15-minute intervals)')
            ax2.set_xticks(tick_positions)
            ax2.set_xticklabels(tick_labels_filtered, rotation=45)
            
            # Add vertical lines for key times
            for hour_mark in [0, 24, 48, 72]:
                ax2.axvline(x=hour_mark, color='gray', linestyle=':', alpha=0.5)
            
            plt.tight_layout()
            plt.savefig(f"{patterns_dir}/{device_name}_pattern.{plot_format}", dpi=plot_dpi, bbox_inches='tight')
            plt.close()

    def _plot_temperature_correlation(self, load_data: pd.DataFrame, output_dir: str,
                                      plot_format: str, plot_dpi: int):
        """Plot temperature vs power correlation."""
        plt.figure(figsize=(10, 6))

        # Scatter plot with trend line
        x = load_data['temperature']
        y = load_data['total_power']

        plt.scatter(x, y, alpha=0.1, s=1)

        # Add trend line
        z = np.polyfit(x, y, 1)
        p = np.poly1d(z)
        plt.plot(x.sort_values(), p(x.sort_values()), "r--", alpha=0.8, linewidth=2)

        correlation = x.corr(y)
        plt.xlabel('Temperature (Â°C)')
        plt.ylabel('Power Consumption (W)')
        plt.title(f'Temperature vs Power Consumption (Correlation: {correlation:.3f})')
        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(f"{output_dir}/temperature_correlation.{plot_format}", dpi=plot_dpi, bbox_inches='tight')
        plt.close()

    def _plot_device_breakdown(self, load_data: pd.DataFrame, output_dir: str,
                               plot_format: str, plot_dpi: int):
        """Plot device consumption breakdown."""
        device_columns = [col for col in load_data.columns if (col.endswith('_power') and not col.startswith("total"))]

        if not device_columns:
            return

        # Calculate total consumption per device
        device_totals = {}
        for col in device_columns:
            device_name = col.replace('_power', '').replace('_', ' ').title()
            device_totals[device_name] = load_data[col].sum() * 0.25 / 1000  # kWh

        # Pie chart
        plt.figure(figsize=(10, 8))
        plt.pie(device_totals.values(), labels=device_totals.keys(), autopct='%1.1f%%', startangle=90)
        plt.title('Energy Consumption by Device')
        plt.axis('equal')

        plt.tight_layout()
        plt.savefig(f"{output_dir}/device_breakdown.{plot_format}", dpi=plot_dpi, bbox_inches='tight')
        plt.close()

    def _plot_monthly_patterns(self, load_data: pd.DataFrame, output_dir: str,
                               plot_format: str, plot_dpi: int):
        """Plot monthly consumption patterns."""
        monthly_consumption = load_data.groupby(load_data.index.month)['total_power'].sum() * 0.25 / 1000

        month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
                       'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

        plt.figure(figsize=(12, 6))
        bars = plt.bar(range(1, len(monthly_consumption) + 1), monthly_consumption.values)
        plt.xlabel('Month')
        plt.ylabel('Total Energy Consumption (kWh)')
        plt.title('Monthly Energy Consumption')
        plt.xticks(range(1, len(monthly_consumption) + 1),
                   [month_names[i-1] for i in monthly_consumption.index])
        plt.grid(True, alpha=0.3, axis='y')

        # Add value labels on bars
        for bar, value in zip(bars, monthly_consumption.values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + value*0.01,
                     f'{value:.0f}', ha='center', va='bottom')

        plt.tight_layout()
        plt.savefig(f"{output_dir}/monthly_patterns.{plot_format}", dpi=plot_dpi, bbox_inches='tight')
        plt.close()

    def export_to_csv(self, load_data: pd.DataFrame, analysis: Dict, filename: str):
        """Export data to CSV format."""
        self.logger.info(f"ðŸ“„ Exporting intelligent analytics to CSV: {filename}")

        # Main data export
        load_data.to_csv(filename)

        # Export analysis summary
        summary_filename = filename.replace('.csv', '_summary.csv')

        # Flatten analysis data for CSV export
        summary_data = []

        # Basic statistics
        for key, value in analysis.get('basic_statistics', {}).items():
            if isinstance(value, dict):
                for subkey, subvalue in value.items():
                    summary_data.append({'Category': key, 'Metric': subkey, 'Value': subvalue})
            else:
                summary_data.append({'Category': 'basic_statistics', 'Metric': key, 'Value': value})

        # Device breakdown
        for device, stats in analysis.get('device_breakdown', {}).items():
            for metric, value in stats.items():
                summary_data.append({'Category': f'device_{device}', 'Metric': metric, 'Value': value})
        
        # Intelligence metrics
        for key, value in analysis.get('intelligence_metrics', {}).items():
            if isinstance(value, (int, float)):
                summary_data.append({'Category': 'intelligence', 'Metric': key, 'Value': value})
        
        # Learning analysis summary
        learning_analysis = analysis.get('learning_analysis', {})
        for key, value in learning_analysis.items():
            if isinstance(value, (int, float)):
                summary_data.append({'Category': 'learning', 'Metric': key, 'Value': value})
        
        # Building efficiency summary
        building_efficiency = analysis.get('building_efficiency', {})
        for key, value in building_efficiency.items():
            if isinstance(value, (int, float)):
                summary_data.append({'Category': 'building_efficiency', 'Metric': key, 'Value': value})

        summary_df = pd.DataFrame(summary_data)
        summary_df.to_csv(summary_filename, index=False)

        self.logger.info(f"Summary exported to: {summary_filename}")

    def export_to_excel(self, load_data: pd.DataFrame, analysis: Dict, filename: str):
        """Export data to Excel format with multiple sheets."""
        self.logger.info(f"ðŸ“ˆ Exporting comprehensive intelligent analytics to Excel: {filename}")

        with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:
            # Main data
            load_data.to_excel(writer, sheet_name='Load_Profile')

            # Basic statistics
            if 'basic_statistics' in analysis:
                stats_df = pd.DataFrame([analysis['basic_statistics']]).T
                stats_df.columns = ['Value']
                stats_df.to_excel(writer, sheet_name='Statistics')

            # Temporal patterns
            if 'temporal_patterns' in analysis:
                patterns = analysis['temporal_patterns']

                # 15-minute interval patterns
                if 'interval_15min' in patterns:
                    interval_df = pd.DataFrame(patterns['interval_15min']).T
                    # Add time labels
                    time_labels = []
                    for hour in range(24):
                        for minute in [0, 15, 30, 45]:
                            time_labels.append(f"{hour:02d}:{minute:02d}")
                    interval_df['Time'] = time_labels[:len(interval_df)]
                    cols = ['Time'] + [col for col in interval_df.columns if col != 'Time']
                    interval_df = interval_df[cols]
                    interval_df.to_excel(writer, sheet_name='15min_Patterns', index=False)

                # Hourly patterns
                if 'hourly' in patterns:
                    hourly_df = pd.DataFrame(patterns['hourly']).T
                    hourly_df.to_excel(writer, sheet_name='Hourly_Patterns')

                if 'monthly' in patterns:
                    monthly_df = pd.DataFrame(patterns['monthly']).T
                    monthly_df.to_excel(writer, sheet_name='Monthly_Patterns')

            # Device breakdown
            if 'device_breakdown' in analysis:
                device_df = pd.DataFrame(analysis['device_breakdown']).T
                device_df.to_excel(writer, sheet_name='Device_Breakdown')

            # Weather correlation
            if 'weather_correlation' in analysis:
                corr_data = []
                for key, value in analysis['weather_correlation'].items():
                    if isinstance(value, dict):
                        for subkey, subvalue in value.items():
                            corr_data.append({'Variable': key, 'Bin/Type': subkey, 'Correlation': subvalue})
                    else:
                        corr_data.append({'Variable': key, 'Bin/Type': 'Overall', 'Correlation': value})

                if corr_data:
                    corr_df = pd.DataFrame(corr_data)
                    corr_df.to_excel(writer, sheet_name='Weather_Correlation', index=False)
            
            # Intelligence metrics
            if 'intelligence_metrics' in analysis:
                intel_df = pd.DataFrame([analysis['intelligence_metrics']]).T
                intel_df.columns = ['Score']
                intel_df.to_excel(writer, sheet_name='Intelligence_Metrics')
            
            # Learning analysis
            if 'learning_analysis' in analysis:
                learning_data = []
                learning_analysis = analysis['learning_analysis']
                
                # Pattern scales
                if 'pattern_scales' in learning_analysis:
                    for scale, metrics in learning_analysis['pattern_scales'].items():
                        for metric, value in metrics.items():
                            learning_data.append({'Scale': scale, 'Metric': metric, 'Value': value})
                
                # Other learning metrics
                for key, value in learning_analysis.items():
                    if key != 'pattern_scales' and isinstance(value, (int, float)):
                        learning_data.append({'Scale': 'Overall', 'Metric': key, 'Value': value})
                    elif key != 'pattern_scales' and isinstance(value, dict):
                        for subkey, subvalue in value.items():
                            learning_data.append({'Scale': key, 'Metric': subkey, 'Value': subvalue})
                
                if learning_data:
                    learning_df = pd.DataFrame(learning_data)
                    learning_df.to_excel(writer, sheet_name='Learning_Analysis', index=False)
            
            # Device discovery
            if 'device_discovery' in analysis:
                discovery_analysis = analysis['device_discovery']
                
                # Discovered devices
                if discovery_analysis.get('discovered_devices'):
                    discovered_df = pd.DataFrame(discovery_analysis['discovered_devices'])
                    discovered_df.to_excel(writer, sheet_name='Discovered_Devices', index=False)
                
                # Discovery confidence
                if discovery_analysis.get('discovery_confidence'):
                    confidence_data = []
                    for device, confidence in discovery_analysis['discovery_confidence'].items():
                        confidence_data.append({'Device': device, 'Confidence': confidence})
                    confidence_df = pd.DataFrame(confidence_data)
                    confidence_df.to_excel(writer, sheet_name='Discovery_Confidence', index=False)
            
            # Building efficiency
            if 'building_efficiency' in analysis:
                efficiency_data = []
                for key, value in analysis['building_efficiency'].items():
                    if isinstance(value, dict):
                        for subkey, subvalue in value.items():
                            efficiency_data.append({'Category': key, 'Metric': subkey, 'Value': subvalue})
                    else:
                        efficiency_data.append({'Category': 'General', 'Metric': key, 'Value': value})
                
                if efficiency_data:
                    efficiency_df = pd.DataFrame(efficiency_data)
                    efficiency_df.to_excel(writer, sheet_name='Building_Efficiency', index=False)

        self.logger.info(f"Excel export completed: {filename}")
    
    def _analyze_intelligence_metrics(self, load_data: pd.DataFrame) -> Dict[str, Any]:
        """Analyze AI intelligence and learning effectiveness metrics."""
        intelligence_metrics = {
            'overall_intelligence_score': self._calculate_intelligence_score(load_data),
            'learning_effectiveness': self._calculate_learning_effectiveness(load_data),
            'pattern_discovery_quality': self._analyze_pattern_discovery_quality(load_data),
            'adaptation_responsiveness': self._calculate_adaptation_responsiveness(load_data),
            'predictive_accuracy': self._calculate_predictive_accuracy(load_data),
            'model_confidence': self._calculate_model_confidence(load_data)
        }
        
        self.intelligence_metrics = intelligence_metrics
        return intelligence_metrics
    
    def _analyze_learning_patterns(self, load_data: pd.DataFrame) -> Dict[str, Any]:
        """Analyze learning patterns and multi-scale pattern discovery."""
        learning_analysis = {
            'pattern_scales': {
                '15_minute': self._analyze_15min_learning(load_data),
                'hourly': self._analyze_hourly_learning(load_data),
                'daily': self._analyze_daily_learning(load_data),
                'weekly': self._analyze_weekly_learning(load_data),
                'seasonal': self._analyze_seasonal_learning(load_data)
            },
            'learning_convergence': self._analyze_learning_convergence(load_data),
            'pattern_stability': self._calculate_pattern_stability(load_data),
            'cross_correlation_analysis': self._analyze_cross_correlations(load_data)
        }
        
        self.learning_analytics = learning_analysis
        return learning_analysis
    
    def _analyze_device_discovery(self, load_data: pd.DataFrame) -> Dict[str, Any]:
        """Analyze device discovery effectiveness and confidence."""
        device_columns = [col for col in load_data.columns if col.endswith('_power')]
        
        discovery_analysis = {
            'discovered_devices': [],
            'discovery_confidence': {},
            'signature_quality': {},
            'device_interactions': {},
            'discovery_metrics': {
                'total_devices_discovered': 0,
                'avg_confidence': 0.0,
                'signature_uniqueness': 0.0
            }
        }
        
        for device_col in device_columns:
            device_name = device_col.replace('_power', '')
            
            # Analyze device signature quality
            signature_quality = self._analyze_device_signature(load_data, device_col)
            discovery_analysis['signature_quality'][device_name] = signature_quality
            
            # Calculate discovery confidence
            confidence = self._calculate_discovery_confidence(load_data, device_col)
            discovery_analysis['discovery_confidence'][device_name] = confidence
            
            # Check if device was discovered vs configured
            device_config = self.config.get('devices', {}).get(device_name, {})
            if device_config.get('discovered', False):
                discovery_analysis['discovered_devices'].append({
                    'name': device_name,
                    'confidence': confidence,
                    'signature_quality': signature_quality
                })
        
        # Calculate overall discovery metrics
        if discovery_analysis['discovered_devices']:
            discovery_analysis['discovery_metrics']['total_devices_discovered'] = len(discovery_analysis['discovered_devices'])
            discovery_analysis['discovery_metrics']['avg_confidence'] = np.mean([d['confidence'] for d in discovery_analysis['discovered_devices']])
        
        self.device_discovery_results = discovery_analysis
        return discovery_analysis
    
    def _analyze_pattern_confidence(self, load_data: pd.DataFrame) -> Dict[str, Any]:
        """Analyze confidence levels in learned patterns."""
        confidence_analysis = {
            'pattern_consistency': self._calculate_pattern_consistency(load_data),
            'temporal_confidence': {
                '15_minute': self._calculate_temporal_confidence(load_data, '15min'),
                'hourly': self._calculate_temporal_confidence(load_data, '1H'),
                'daily': self._calculate_temporal_confidence(load_data, '1D')
            },
            'device_pattern_confidence': {},
            'weather_correlation_confidence': self._calculate_weather_correlation_confidence(load_data)
        }
        
        # Calculate confidence for each device pattern
        device_columns = [col for col in load_data.columns if col.endswith('_power')]
        for device_col in device_columns:
            device_name = device_col.replace('_power', '')
            confidence_analysis['device_pattern_confidence'][device_name] = self._calculate_device_pattern_confidence(load_data, device_col)
        
        self.pattern_confidence = confidence_analysis
        return confidence_analysis
    
    def _analyze_building_efficiency(self, load_data: pd.DataFrame) -> Dict[str, Any]:
        """Analyze building efficiency and thermal characteristics."""
        building_config = self.config.get('building', {})
        
        efficiency_analysis = {
            'thermal_efficiency': self._calculate_thermal_efficiency(load_data),
            'insulation_effectiveness': self._analyze_insulation_effectiveness(load_data),
            'hvac_efficiency': self._analyze_hvac_efficiency(load_data),
            'building_performance_metrics': {
                'energy_intensity': self._calculate_energy_intensity(load_data),
                'thermal_responsiveness': self._calculate_thermal_responsiveness(load_data),
                'baseline_efficiency': self._calculate_baseline_efficiency(load_data)
            },
            'efficiency_trends': self._analyze_efficiency_trends(load_data)
        }
        
        return efficiency_analysis
    
    def _analyze_adaptation_effectiveness(self, load_data: pd.DataFrame) -> Dict[str, Any]:
        """Analyze how effectively the AI system adapts to changes."""
        adaptation_analysis = {
            'adaptation_rate': self._calculate_adaptation_rate(load_data),
            'response_time': self._calculate_response_time(load_data),
            'adaptation_accuracy': self._calculate_adaptation_accuracy(load_data),
            'learning_speed': self._calculate_learning_speed(load_data),
            'stability_after_adaptation': self._calculate_adaptation_stability(load_data)
        }
        
        return adaptation_analysis
    
    # Helper methods for intelligent analytics
    def _calculate_intelligence_score(self, load_data: pd.DataFrame) -> float:
        """Calculate overall intelligence score based on multiple factors."""
        scores = []
        
        # Pattern consistency
        consistency = self._calculate_pattern_consistency(load_data)
        scores.append(consistency * 0.3)
        
        # Realism factor
        realism = self._calculate_realism_factor(load_data)
        scores.append(realism * 0.3)
        
        # Predictive capability
        prediction_accuracy = self._calculate_predictive_accuracy(load_data)
        scores.append(prediction_accuracy * 0.2)
        
        # Adaptation effectiveness
        adaptation = self._calculate_adaptation_rate(load_data)
        scores.append(adaptation * 0.2)
        
        return np.mean(scores) * 100  # Scale to 0-100
    
    def _calculate_realism_factor(self, load_data: pd.DataFrame) -> float:
        """Calculate how realistic the energy patterns are."""
        realism_factors = []
        
        # Smooth transitions (no sudden jumps)
        power_diff = load_data['total_power'].diff().abs()
        max_reasonable_change = load_data['total_power'].mean() * 0.3
        smooth_transitions = (power_diff <= max_reasonable_change).mean()
        realism_factors.append(smooth_transitions)
        
        # Natural variations (not too regular)
        hourly_std = load_data.groupby(load_data.index.hour)['total_power'].std().mean()
        natural_variation = min(hourly_std / load_data['total_power'].mean(), 1.0)
        realism_factors.append(natural_variation)
        
        # Weather correlation realism
        temp_corr = abs(load_data['total_power'].corr(load_data['temperature']))
        weather_realism = min(temp_corr * 2, 1.0)  # Scale correlation to realism
        realism_factors.append(weather_realism)
        
        return np.mean(realism_factors)
    
    def _calculate_learning_confidence(self, load_data: pd.DataFrame) -> float:
        """Calculate confidence in learned patterns."""
        # Pattern stability over time
        pattern_stability = self._calculate_pattern_stability(load_data)
        
        # Consistency across similar conditions
        consistency = self._calculate_pattern_consistency(load_data)
        
        # Amount of data available for learning
        data_sufficiency = min(len(load_data) / (30 * 24 * 4), 1.0)  # 30 days of 15-min data
        
        return np.mean([pattern_stability, consistency, data_sufficiency])
    
    def _calculate_device_intelligence(self, load_data: pd.DataFrame, device_col: str) -> float:
        """Calculate intelligence score for a specific device."""
        if device_col not in load_data.columns:
            return 0.0
        
        device_data = load_data[device_col]
        
        # Pattern regularity
        hourly_patterns = load_data.groupby(load_data.index.hour)[device_col].mean()
        pattern_regularity = 1.0 - (hourly_patterns.std() / hourly_patterns.mean()) if hourly_patterns.mean() > 0 else 0.0
        
        # Response to temperature (for HVAC devices)
        temp_response = abs(device_data.corr(load_data['temperature'])) if 'temperature' in load_data.columns else 0.5
        
        # Realistic cycling behavior
        cycling_realism = self._analyze_cycling_behavior(device_data)
        
        return np.mean([pattern_regularity, temp_response, cycling_realism]) * 100
    
    def _calculate_device_learning_confidence(self, device_name: str) -> float:
        """Calculate learning confidence for a specific device."""
        device_config = self.config.get('devices', {}).get(device_name, {})
        
        # Check if device has learned parameters
        has_learned_params = any(key.startswith('learned_') for key in device_config.keys())
        
        # Discovery confidence if device was discovered
        discovery_confidence = device_config.get('discovery_confidence', 0.5)
        
        # Pattern enhancement indicator
        pattern_enhanced = device_config.get('pattern_enhanced', False)
        
        confidence_factors = []
        if has_learned_params:
            confidence_factors.append(0.8)
        if discovery_confidence > 0.7:
            confidence_factors.append(discovery_confidence)
        if pattern_enhanced:
            confidence_factors.append(0.7)
        
        return np.mean(confidence_factors) if confidence_factors else 0.5
    
    def _calculate_device_adaptation(self, device_name: str) -> float:
        """Calculate adaptation effectiveness for a device."""
        # This would be enhanced with actual adaptation tracking
        # For now, return a baseline based on device type
        device_type = device_name.lower()
        
        adaptation_rates = {
            'heater': 0.8,
            'air_conditioner': 0.8,
            'refrigeration': 0.6,
            'general_load': 0.7,
            'lighting': 0.9,
            'water_heater': 0.7
        }
        
        return adaptation_rates.get(device_type, 0.6)
    
    def _calculate_device_realism(self, load_data: pd.DataFrame, device_col: str) -> float:
        """Calculate realism score for a specific device."""
        if device_col not in load_data.columns:
            return 0.0
        
        device_data = load_data[device_col]
        
        # Smooth transitions
        transitions = device_data.diff().abs()
        max_change = device_data.max() * 0.2  # Max 20% change per 15-min
        smooth_score = (transitions <= max_change).mean() if max_change > 0 else 1.0
        
        # Natural cycling for appropriate devices
        cycling_score = self._analyze_cycling_behavior(device_data)
        
        # Appropriate power levels (not constantly at max)
        utilization = device_data.mean() / device_data.max() if device_data.max() > 0 else 0.0
        utilization_score = 1.0 - abs(utilization - 0.6)  # Optimal around 60% utilization
        
        return np.mean([smooth_score, cycling_score, max(utilization_score, 0.0)]) * 100
    
    def _analyze_cycling_behavior(self, device_data: pd.Series) -> float:
        """Analyze if device shows realistic cycling behavior."""
        # Simple cycling analysis
        if device_data.max() == 0:
            return 1.0  # No data, assume realistic
        
        # Look for on/off patterns
        on_periods = (device_data > device_data.max() * 0.1).astype(int)
        transitions = on_periods.diff().abs().sum()
        
        # Realistic cycling should have some transitions but not too many
        expected_transitions = len(device_data) / 100  # Rough heuristic
        cycling_score = 1.0 - abs(transitions - expected_transitions) / expected_transitions
        
        return max(cycling_score, 0.0)
    
    # Placeholder methods for comprehensive analytics (would be fully implemented)
    def _calculate_learning_effectiveness(self, load_data: pd.DataFrame) -> float:
        return 0.8  # Placeholder
    
    def _analyze_pattern_discovery_quality(self, load_data: pd.DataFrame) -> float:
        return 0.75  # Placeholder
    
    def _calculate_adaptation_responsiveness(self, load_data: pd.DataFrame) -> float:
        return 0.7  # Placeholder
    
    def _calculate_predictive_accuracy(self, load_data: pd.DataFrame) -> float:
        return 0.82  # Placeholder
    
    def _calculate_model_confidence(self, load_data: pd.DataFrame) -> float:
        return 0.85  # Placeholder
    
    def _analyze_15min_learning(self, load_data: pd.DataFrame) -> Dict:
        return {'pattern_quality': 0.8, 'learning_rate': 0.05}
    
    def _analyze_hourly_learning(self, load_data: pd.DataFrame) -> Dict:
        return {'pattern_quality': 0.85, 'learning_rate': 0.03}
    
    def _analyze_daily_learning(self, load_data: pd.DataFrame) -> Dict:
        return {'pattern_quality': 0.9, 'learning_rate': 0.02}
    
    def _analyze_weekly_learning(self, load_data: pd.DataFrame) -> Dict:
        return {'pattern_quality': 0.75, 'learning_rate': 0.01}
    
    def _analyze_seasonal_learning(self, load_data: pd.DataFrame) -> Dict:
        return {'pattern_quality': 0.7, 'learning_rate': 0.005}
    
    def _analyze_learning_convergence(self, load_data: pd.DataFrame) -> Dict:
        return {'converged': True, 'iterations': 25, 'final_error': 0.02}
    
    def _calculate_pattern_stability(self, load_data: pd.DataFrame) -> float:
        # Analyze how stable patterns are over time
        if len(load_data) < 48:  # Less than 2 days
            return 0.5
        
        # Split data in half and compare patterns
        mid_point = len(load_data) // 2
        first_half = load_data.iloc[:mid_point]
        second_half = load_data.iloc[mid_point:]
        
        # Compare hourly patterns
        pattern1 = first_half.groupby(first_half.index.hour)['total_power'].mean()
        pattern2 = second_half.groupby(second_half.index.hour)['total_power'].mean()
        
        # Calculate correlation between patterns
        correlation = pattern1.corr(pattern2)
        return max(correlation, 0.0) if not np.isnan(correlation) else 0.5
    
    def _analyze_cross_correlations(self, load_data: pd.DataFrame) -> Dict:
        return {'device_interactions': 0.3, 'weather_devices': 0.7}
    
    def _analyze_device_signature(self, load_data: pd.DataFrame, device_col: str) -> float:
        return 0.8  # Placeholder
    
    def _calculate_discovery_confidence(self, load_data: pd.DataFrame, device_col: str) -> float:
        return 0.75  # Placeholder
    
    def _calculate_pattern_consistency(self, load_data: pd.DataFrame) -> float:
        # Analyze consistency of daily patterns
        daily_patterns = []
        for day in load_data.groupby(load_data.index.date):
            day_data = day[1]
            if len(day_data) >= 24:  # At least 24 data points
                hourly_avg = day_data.groupby(day_data.index.hour)['total_power'].mean()
                daily_patterns.append(hourly_avg.values)
        
        if len(daily_patterns) < 2:
            return 0.5
        
        # Calculate average correlation between daily patterns
        correlations = []
        for i in range(len(daily_patterns)):
            for j in range(i+1, len(daily_patterns)):
                corr = np.corrcoef(daily_patterns[i], daily_patterns[j])[0, 1]
                if not np.isnan(corr):
                    correlations.append(corr)
        
        return np.mean(correlations) if correlations else 0.5
    
    def _calculate_temporal_confidence(self, load_data: pd.DataFrame, freq: str) -> float:
        return 0.8  # Placeholder
    
    def _calculate_device_pattern_confidence(self, load_data: pd.DataFrame, device_col: str) -> float:
        return 0.75  # Placeholder
    
    def _calculate_weather_correlation_confidence(self, load_data: pd.DataFrame) -> float:
        return 0.85  # Placeholder
    
    def _calculate_thermal_efficiency(self, load_data: pd.DataFrame) -> float:
        return 0.7  # Placeholder
    
    def _analyze_insulation_effectiveness(self, load_data: pd.DataFrame) -> float:
        return 0.8  # Placeholder
    
    def _analyze_hvac_efficiency(self, load_data: pd.DataFrame) -> float:
        return 0.75  # Placeholder
    
    def _calculate_energy_intensity(self, load_data: pd.DataFrame) -> float:
        building_config = self.config.get('building', {})
        square_meters = building_config.get('square_meters', 120)
        total_energy = load_data['total_power'].sum() * 0.25 / 1000  # kWh
        days = (load_data.index.max() - load_data.index.min()).days + 1
        return total_energy / (square_meters * days)  # kWh/mÂ²/day
    
    def _calculate_thermal_responsiveness(self, load_data: pd.DataFrame) -> float:
        return 0.6  # Placeholder
    
    def _calculate_baseline_efficiency(self, load_data: pd.DataFrame) -> float:
        return 0.7  # Placeholder
    
    def _analyze_efficiency_trends(self, load_data: pd.DataFrame) -> Dict:
        return {'trend': 'improving', 'rate': 0.02}  # Placeholder
    
    def _calculate_adaptation_rate(self, load_data: pd.DataFrame) -> float:
        return 0.05  # Placeholder
    
    def _calculate_response_time(self, load_data: pd.DataFrame) -> float:
        return 2.5  # hours, placeholder
    
    def _calculate_adaptation_accuracy(self, load_data: pd.DataFrame) -> float:
        return 0.85  # Placeholder
    
    def _calculate_learning_speed(self, load_data: pd.DataFrame) -> float:
        return 0.1  # Placeholder
    
    def _calculate_adaptation_stability(self, load_data: pd.DataFrame) -> float:
        return 0.9  # Placeholder
    
    def _plot_intelligence_metrics(self, load_data: pd.DataFrame, output_dir: str,
                                  plot_format: str, plot_dpi: int):
        """Plot intelligence and learning metrics visualization."""
        if not hasattr(self, 'intelligence_metrics') or not self.intelligence_metrics:
            return
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        # Intelligence scores radar chart (simplified as bar chart)
        metrics = list(self.intelligence_metrics.keys())
        values = [self.intelligence_metrics[m] if isinstance(self.intelligence_metrics[m], (int, float)) else 0.5 for m in metrics]
        
        ax1.bar(range(len(metrics)), values, alpha=0.7)
        ax1.set_title('Intelligence Metrics Overview')
        ax1.set_xticks(range(len(metrics)))
        ax1.set_xticklabels([m.replace('_', ' ').title() for m in metrics], rotation=45)
        ax1.set_ylim(0, 1)
        ax1.grid(True, alpha=0.3)
        
        # Learning effectiveness over time (placeholder)
        time_points = range(10)
        learning_progress = [0.2 + 0.6 * (1 - np.exp(-x/3)) for x in time_points]
        ax2.plot(time_points, learning_progress, marker='o', linewidth=2)
        ax2.set_title('Learning Progress Over Time')
        ax2.set_xlabel('Training Iterations')
        ax2.set_ylabel('Learning Effectiveness')
        ax2.grid(True, alpha=0.3)
        
        # Adaptation responsiveness
        response_categories = ['Temperature', 'Occupancy', 'Weather', 'Time']
        response_values = [0.8, 0.7, 0.75, 0.9]
        ax3.barh(response_categories, response_values, alpha=0.7)
        ax3.set_title('Adaptation Responsiveness by Category')
        ax3.set_xlim(0, 1)
        ax3.grid(True, alpha=0.3)
        
        # Model confidence distribution
        confidence_data = np.random.beta(8, 2, 1000)  # Placeholder distribution
        ax4.hist(confidence_data, bins=30, alpha=0.7, density=True)
        ax4.set_title('Model Confidence Distribution')
        ax4.set_xlabel('Confidence Level')
        ax4.set_ylabel('Density')
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f"{output_dir}/intelligence_metrics.{plot_format}", dpi=plot_dpi, bbox_inches='tight')
        plt.close()
    
    def _plot_learning_analysis(self, load_data: pd.DataFrame, output_dir: str,
                               plot_format: str, plot_dpi: int):
        """Plot learning analysis and multi-scale patterns."""
        if not hasattr(self, 'learning_analytics') or not self.learning_analytics:
            return
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        # Multi-scale pattern quality
        scales = ['15_minute', 'hourly', 'daily', 'weekly', 'seasonal']
        pattern_qualities = [0.8, 0.85, 0.9, 0.75, 0.7]  # Placeholder values
        
        ax1.plot(scales, pattern_qualities, marker='o', linewidth=2, markersize=8)
        ax1.set_title('Pattern Quality Across Time Scales')
        ax1.set_ylabel('Pattern Quality Score')
        ax1.set_ylim(0, 1)
        ax1.grid(True, alpha=0.3)
        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
        
        # Learning convergence
        iterations = range(1, 51)
        error_progression = [0.5 * np.exp(-x/10) + 0.02 for x in iterations]
        ax2.plot(iterations, error_progression, linewidth=2)
        ax2.set_title('Learning Convergence')
        ax2.set_xlabel('Iterations')
        ax2.set_ylabel('Error Rate')
        ax2.set_yscale('log')
        ax2.grid(True, alpha=0.3)
        
        # Pattern stability comparison - now dynamic
        if self.config_manager:
            devices_config = self.config_manager.get_all_devices()
            devices = list(devices_config.keys())[:4]  # Take first 4 for visualization
        else:
            devices = ['Device1', 'Device2', 'Device3', 'Device4']
        stability_scores = [0.85, 0.82, 0.9, 0.75]  # Placeholder - could be calculated from actual data
        colors = ['red', 'blue', 'green', 'orange']
        
        bars = ax3.bar(devices, stability_scores, color=colors, alpha=0.7)
        ax3.set_title('Pattern Stability by Device')
        ax3.set_ylabel('Stability Score')
        ax3.set_ylim(0, 1)
        ax3.grid(True, alpha=0.3)
        
        # Cross-correlation heatmap (simplified)
        corr_matrix = np.random.rand(4, 4)  # Placeholder correlation matrix
        np.fill_diagonal(corr_matrix, 1.0)
        
        im = ax4.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)
        ax4.set_title('Device Interaction Cross-Correlations')
        ax4.set_xticks(range(len(devices)))
        ax4.set_yticks(range(len(devices)))
        ax4.set_xticklabels(devices)
        ax4.set_yticklabels(devices)
        plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45)
        
        # Add colorbar
        cbar = plt.colorbar(im, ax=ax4, shrink=0.8)
        cbar.set_label('Correlation')
        
        plt.tight_layout()
        plt.savefig(f"{output_dir}/learning_analysis.{plot_format}", dpi=plot_dpi, bbox_inches='tight')
        plt.close()
    
    def _plot_device_intelligence(self, load_data: pd.DataFrame, output_dir: str,
                                 plot_format: str, plot_dpi: int):
        """Plot device-specific intelligence metrics."""
        device_columns = [col for col in load_data.columns if col.endswith('_power')]
        
        if not device_columns:
            return
        
        device_names = [col.replace('_power', '').replace('_', ' ').title() for col in device_columns]
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        # Device intelligence scores
        intelligence_scores = []
        for device_col in device_columns:
            score = self._calculate_device_intelligence(load_data, device_col)
            intelligence_scores.append(score)
        
        colors = plt.cm.viridis(np.linspace(0, 1, len(device_names)))
        bars1 = ax1.bar(device_names, intelligence_scores, color=colors, alpha=0.8)
        ax1.set_title('Device Intelligence Scores')
        ax1.set_ylabel('Intelligence Score')
        ax1.set_ylim(0, 100)
        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
        ax1.grid(True, alpha=0.3)
        
        # Add value labels on bars
        for bar, score in zip(bars1, intelligence_scores):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 1,
                    f'{score:.0f}', ha='center', va='bottom')
        
        # Device realism scores
        realism_scores = []
        for device_col in device_columns:
            score = self._calculate_device_realism(load_data, device_col)
            realism_scores.append(score)
        
        bars2 = ax2.bar(device_names, realism_scores, color=colors, alpha=0.8)
        ax2.set_title('Device Realism Scores')
        ax2.set_ylabel('Realism Score')
        ax2.set_ylim(0, 100)
        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)
        ax2.grid(True, alpha=0.3)
        
        # Learning confidence by device
        learning_confidence = []
        for device_col in device_columns:
            device_name = device_col.replace('_power', '')
            confidence = self._calculate_device_learning_confidence(device_name)
            learning_confidence.append(confidence * 100)
        
        bars3 = ax3.bar(device_names, learning_confidence, color=colors, alpha=0.8)
        ax3.set_title('Learning Confidence by Device')
        ax3.set_ylabel('Confidence (%)')
        ax3.set_ylim(0, 100)
        plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45)
        ax3.grid(True, alpha=0.3)
        
        # Device discovery confidence (for discovered devices)
        discovery_confidence = []
        device_types = []
        
        for device_col in device_columns:
            device_name = device_col.replace('_power', '')
            device_config = self.config.get('devices', {}).get(device_name, {})
            if device_config.get('discovered', False):
                confidence = device_config.get('discovery_confidence', 0.5) * 100
                discovery_confidence.append(confidence)
                device_types.append(device_name.replace('_', ' ').title())
        
        if discovery_confidence:
            bars4 = ax4.bar(device_types, discovery_confidence, 
                           color=colors[:len(device_types)], alpha=0.8)
            ax4.set_title('Discovery Confidence (AI-Discovered Devices)')
            ax4.set_ylabel('Discovery Confidence (%)')
            ax4.set_ylim(0, 100)
            plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45)
            ax4.grid(True, alpha=0.3)
        else:
            ax4.text(0.5, 0.5, 'No AI-Discovered Devices', 
                    transform=ax4.transAxes, ha='center', va='center',
                    fontsize=12, style='italic')
            ax4.set_title('Discovery Confidence (AI-Discovered Devices)')
        
        plt.tight_layout()
        plt.savefig(f"{output_dir}/device_intelligence.{plot_format}", dpi=plot_dpi, bbox_inches='tight')
        plt.close()